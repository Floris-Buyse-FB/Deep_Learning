{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgXQSJ1r2gk40mbuZGeYG1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sodsrvxBVIdN"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["# Fetch the data, same as in book\n","shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n","filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n","with open(filepath) as f:\n","    shakespeare_text = f.read() # shakespeare_text is now a string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElTCzTmn-U1a","executionInfo":{"status":"ok","timestamp":1705504693817,"user_tz":-60,"elapsed":1151,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"26b0d000-93b1-4ccb-c80e-2bbaffd09c67"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://homl.info/shakespeare\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Split on characters, keep punctuation as well as upper- and lowercase letters\n","text_vec_layer = tf.keras.layers.TextVectorization(\n","  split=\"character\", standardize=None) # also keep upper case etc.\n","# shakespeare_text is a string and adapt expects a dataset or list\n","text_vec_layer.adapt([shakespeare_text])\n","encoded = text_vec_layer([shakespeare_text])[0]"],"metadata":{"id":"2tgxBa6W-YMX","executionInfo":{"status":"ok","timestamp":1705504694707,"user_tz":-60,"elapsed":890,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["print(text_vec_layer.get_vocabulary())\n","print(len(text_vec_layer.get_vocabulary()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjH0nr9H-rER","executionInfo":{"status":"ok","timestamp":1705504694707,"user_tz":-60,"elapsed":2,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"c1b4a8d6-0189-41d5-bc07-3fa2b19d88cf"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]', ' ', 'e', 't', 'o', 'a', 'h', 's', 'r', 'n', 'i', '\\n', 'l', 'd', 'u', 'm', 'y', ',', 'w', 'f', 'c', 'g', 'I', 'b', 'p', ':', '.', 'A', 'v', 'k', 'T', \"'\", 'E', 'O', 'N', 'R', 'S', 'L', 'C', ';', 'W', 'U', 'H', 'M', 'B', '?', 'G', '!', 'D', '-', 'F', 'Y', 'P', 'K', 'V', 'j', 'q', 'x', 'z', 'J', 'Q', 'Z', 'X', '3', '&', '$']\n","67\n"]}]},{"cell_type":"code","source":["encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n","              # use broadcasting to subtract 2 from all values\n","n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 65\n","dataset_size = len(encoded)  # total number of chars = 1,115,394"],"metadata":{"id":"SdKSYdFoAHwi","executionInfo":{"status":"ok","timestamp":1705504703597,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n","    ds = tf.data.Dataset.from_tensor_slices(sequence)\n","    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n","    if shuffle:\n","        ds = ds.shuffle(100_000, seed=seed)\n","    ds = ds.batch(batch_size)\n","    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"],"metadata":{"id":"g0D4xiFt_Aqa","executionInfo":{"status":"ok","timestamp":1705504524298,"user_tz":-60,"elapsed":207,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["SEQ_LENGTH = 100"],"metadata":{"id":"ACXhGO5KALAM","executionInfo":{"status":"ok","timestamp":1705504720071,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Create training, validation and test data set. Same as in book.\n","tf.random.set_seed(42)\n","train_set = to_dataset(encoded[:1_000_000], length=SEQ_LENGTH, shuffle=True,\n","                       seed=42)\n","valid_set = to_dataset(encoded[1_000_000:1_060_000], length=SEQ_LENGTH)\n","test_set = to_dataset(encoded[1_060_000:], length=SEQ_LENGTH)"],"metadata":{"id":"NGwFlHwI_C-N","executionInfo":{"status":"ok","timestamp":1705504721548,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["for x, y in train_set.take(1):\n","  print(x.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpTn4xRl_deb","executionInfo":{"status":"ok","timestamp":1705504747711,"user_tz":-60,"elapsed":24007,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"7c71334e-2c7b-4766-c8d2-949318d17d66"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 100) (32, 100)\n"]}]},{"cell_type":"code","source":["class BertEncoderBlock(tf.keras.layers.Layer):\n","  def __init__(self, num_heads, embed_size, **kwargs):\n","    super().__init__(**kwargs)\n","\n","    self.num_heads = num_heads\n","    self.embed_size = embed_size\n","    self.multi_head_attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size//num_heads)\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","    self.dense1 = tf.keras.layers.Dense(units=4*embed_size, activation=\"relu\")\n","    self.dense2 = tf.keras.layers.Dense(units=embed_size)\n","\n","  def call(self, inputs):\n","    # Multi-Head (Self)-Attention Block\n","    skip = inputs\n","    inputs = self.multi_head_attention(\n","        query=inputs,\n","        value=inputs,\n","        use_causal_mask=False\n","    )\n","    inputs = self.layer_norm(\n","        tf.keras.layers.Add()([inputs, skip])\n","    )\n","\n","    # Feedforward block\n","    skip = inputs\n","    inputs = self.dense1(inputs)\n","    inputs = self.dense2(inputs)\n","    inputs = self.layer_norm(\n","        tf.keras.layers.Add()([inputs, skip])\n","    )\n","\n","    return inputs"],"metadata":{"id":"5xRkKkoY4E3u","executionInfo":{"status":"ok","timestamp":1705504747712,"user_tz":-60,"elapsed":3,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class BERTModel(tf.keras.Model):\n","\n","  def __init__(self, n_tokens, embed_size, num_blocks, num_heads, max_seq_length, **kwargs):\n","\n","        super().__init__(**kwargs)\n","\n","        self.num_heads = num_heads\n","        self.max_seq_length = max_seq_length\n","\n","        # Layers\n","        self.embed_layer = tf.keras.layers.Embedding(\n","            input_dim=n_tokens,\n","            output_dim=embed_size,\n","            name='embedding')\n","        self.pos_embed_layer = tf.keras.layers.Embedding(\n","            input_dim=max_seq_length,\n","            output_dim=embed_size,\n","            name='positional_embedding')\n","        self.encoder_blocks = [BertEncoderBlock(\n","            num_heads=num_heads,\n","            embed_size=embed_size,\n","            name='BertBlock' + str(i)) for i in range(num_blocks)]\n","        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","\n","  def call(self, inputs):\n","\n","        embeddings = self.embed_layer(inputs)\n","        pos_embeddings = self.pos_embed_layer(tf.range(self.max_seq_length))\n","\n","\n","        embeddings = embeddings + pos_embeddings # Rely on broadcasting\n","\n","        for encoder_block in self.encoder_blocks:\n","            embeddings = encoder_block(embeddings)\n","\n","        output = self.layer_norm(embeddings)\n","\n","        return output"],"metadata":{"id":"NsFMGoeD6DHp","executionInfo":{"status":"ok","timestamp":1705504747712,"user_tz":-60,"elapsed":2,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["n_tokens = 65\n","embed_size=32\n","num_blocks=2\n","num_heads=4\n","\n","model = BERTModel(n_tokens=n_tokens, embed_size=embed_size, num_blocks=num_blocks, num_heads=num_heads, max_seq_length=SEQ_LENGTH)"],"metadata":{"id":"Vud9SgdY8W9m","executionInfo":{"status":"ok","timestamp":1705504747712,"user_tz":-60,"elapsed":2,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["for x, y in train_set.take(1):\n","  print(x.shape)\n","  print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3wl5-f99ar5","executionInfo":{"status":"ok","timestamp":1705504771140,"user_tz":-60,"elapsed":23430,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"d79b4f2f-e33f-46bc-a411-388c9b8b8dc3"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 100)\n","(32, 100, 32)\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_xkT2LLAYgC","executionInfo":{"status":"ok","timestamp":1705504777610,"user_tz":-60,"elapsed":235,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"810ba7fa-fbf8-4d24-b0f6-ef27e9d0a689"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"bert_model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  2080      \n","                                                                 \n"," positional_embedding (Embe  multiple                  3200      \n"," dding)                                                          \n","                                                                 \n"," BertBlock0 (BertEncoderBlo  multiple                  12640     \n"," ck)                                                             \n","                                                                 \n"," BertBlock1 (BertEncoderBlo  multiple                  12640     \n"," ck)                                                             \n","                                                                 \n"," layer_normalization_23 (La  multiple                  64        \n"," yerNormalization)                                               \n","                                                                 \n","=================================================================\n","Total params: 30624 (119.62 KB)\n","Trainable params: 30624 (119.62 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(\n","    optimizer='nadam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=[\"accuracy\"]\n",")"],"metadata":{"id":"pNpTBNg9Acsn","executionInfo":{"status":"ok","timestamp":1705504788670,"user_tz":-60,"elapsed":2,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=2,\n","    restore_best_weights=True\n",")\n","model.fit(train_set, validation_data=valid_set, epochs=20, callbacks=[early_stopping])"],"metadata":{"id":"Rv1WsXzEAekj"},"execution_count":null,"outputs":[]}]}