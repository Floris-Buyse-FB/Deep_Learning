{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMi4plv0XSpJ9HjDOuLi0Dd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"GBtlYmPKr-aL","executionInfo":{"status":"ok","timestamp":1705164119459,"user_tz":-60,"elapsed":5453,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["class GPTDecoderBlock(tf.keras.layers.Layer) :\n","  def __init__(self, num_heads, embed_size, **kwargs):\n","    super().__init__(**kwargs)\n","\n","    self.num_heads = num_heads\n","    self.embed_size = embed_size\n","    self.multi_head_attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size//num_heads)\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","    self.dense1 = tf.keras.layers.Dense(units=4*embed_size, activation=\"relu\")\n","    self.dense2 = tf.keras.layers.Dense(units=embed_size)\n","\n","\n","  def call(self, inputs):\n","    # Masked Multi-Head (Self)-Attention Block\n","    skip = inputs\n","    inputs = self.multi_head_attention(\n","        query=inputs,\n","        value=inputs,\n","        use_causal_mask=True\n","    )\n","    inputs = self.layer_norm(\n","        tf.keras.layers.Add()([inputs, skip])\n","    )\n","\n","    # Feedforward block\n","    skip = inputs\n","    inputs = self.dense1(inputs)\n","    inputs = self.dense2(inputs)\n","    inputs = self.layer_norm(\n","        tf.keras.layers.Add()([inputs, skip])\n","    )\n","\n","    return inputs"],"metadata":{"id":"qLzZkg35s28-","executionInfo":{"status":"ok","timestamp":1705165651819,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["X = tf.constant(0., shape=(2, 10, 64))\n","block = GPTDecoderBlock(num_heads=4, embed_size=64)\n","block(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H3bvfFJykX_","executionInfo":{"status":"ok","timestamp":1705165660544,"user_tz":-60,"elapsed":2,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"8691eae3-d3a0-4f8e-f035-cb8daddca89c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 10, 64), dtype=float32, numpy=\n","array([[[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["url = \"https://homl.info/shakespeare\"\n","filepath = tf.keras.utils.get_file(\"shakespeare.txt\", url)\n","with open(filepath) as f:\n","  text = f.read()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1xi1oL5zfkz","executionInfo":{"status":"ok","timestamp":1705165901500,"user_tz":-60,"elapsed":971,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"7b847a2a-f383-4ca4-9a06-437934e971b8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://homl.info/shakespeare\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n","text_vec_layer.adapt([text])"],"metadata":{"id":"bk9Pt5qvzkoq","executionInfo":{"status":"ok","timestamp":1705165903574,"user_tz":-60,"elapsed":705,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["encoded = text_vec_layer([text])[0]\n","encoded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euckOj4jzuj-","executionInfo":{"status":"ok","timestamp":1705165928484,"user_tz":-60,"elapsed":464,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"7844fb43-f606-4a91-aab3-bc7f01224656"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["len(text_vec_layer.get_vocabulary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzrLeJpVz0aQ","executionInfo":{"status":"ok","timestamp":1705165975185,"user_tz":-60,"elapsed":182,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"5474e4ba-05da-4076-de69-2292adb9a91f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["41"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["encoded -= 2\n","n_tokens = text_vec_layer.vocabulary_size() - 2\n","dataset_size = len(encoded)"],"metadata":{"id":"Hgv7SHxbz_P2","executionInfo":{"status":"ok","timestamp":1705166060872,"user_tz":-60,"elapsed":175,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n","  ds = tf.data.Dataset.from_tensor_slices(sequence)\n","  ds = ds.window(length + 1, shift=1, drop_remainder=True)\n","  ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n","  if shuffle:\n","    ds = ds.shuffle(100_000, seed=seed)\n","  ds = ds.batch(batch_size)\n","  return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"],"metadata":{"id":"uQkZor0-0cLx","executionInfo":{"status":"ok","timestamp":1705166117659,"user_tz":-60,"elapsed":199,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["SEQ_LENGTH = 100\n","tf.random.set_seed(42)\n","train_set = to_dataset (encoded [:1_000_000], length=SEQ_LENGTH, shuffle=True, seed=42)\n","valid_set = to_dataset (encoded [1_000_000:1_060_000], length=SEQ_LENGTH)\n","test_set = to_dataset(encoded [1_060_000:], length=SEQ_LENGTH)"],"metadata":{"id":"U_U2IABW0gOR","executionInfo":{"status":"ok","timestamp":1705167032156,"user_tz":-60,"elapsed":458,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class GPTModel(tf.keras.Model):\n","\n","    def __init__(self, n_tokens, embed_size, num_blocks, num_heads, max_seq_length, **kwargs):\n","\n","        super().__init__(**kwargs)\n","\n","        self.num_heads = num_heads\n","        self.max_seq_length = max_seq_length\n","\n","        # Layers\n","        self.embed_layer = tf.keras.layers.Embedding(\n","            input_dim=n_tokens,\n","            output_dim=embed_size,\n","            name='embedding')\n","        self.pos_embed_layer = tf.keras.layers.Embedding(\n","            input_dim=max_seq_length,\n","            output_dim=embed_size,\n","            name='positional_embedding')\n","        #self.add_layer = tf.keras.layers.Add()\n","        self.decoder_blocks = [GPTDecoderBlock(\n","            num_heads=num_heads,\n","            embed_size=embed_size,\n","            name='GPTBlock' + str(i)) for i in range(num_blocks)]\n","        self.dense_layer = tf.keras.layers.Dense(\n","            units=n_tokens,\n","            activation='softmax',\n","            name='output')\n","\n","    def call(self, inputs):\n","\n","        embeddings = self.embed_layer(inputs)\n","\n","        pos_embeddings = self.pos_embed_layer(tf.range(self.max_seq_length))\n","\n","\n","        embeddings = embeddings + pos_embeddings # Rely on broadcasting\n","\n","        for decoder_block in self.decoder_blocks:\n","            embeddings = decoder_block(embeddings)\n","\n","        output = self.dense_layer(embeddings)\n","\n","        return output"],"metadata":{"id":"J8vOxTei32db","executionInfo":{"status":"ok","timestamp":1705167006207,"user_tz":-60,"elapsed":194,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["EMBED_SIZE = 32\n","NUM_HEADS = 4\n","NUM_BLOCKS = 2"],"metadata":{"id":"DYhk0zMa27Zu","executionInfo":{"status":"ok","timestamp":1705166812585,"user_tz":-60,"elapsed":183,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["model = GPTModel(n_tokens=n_tokens, embed_size=EMBED_SIZE, num_blocks=NUM_BLOCKS, num_heads=NUM_HEADS, max_seq_length=SEQ_LENGTH)"],"metadata":{"id":"OYtyzN0B3Lig","executionInfo":{"status":"ok","timestamp":1705167008719,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C27JDTDj3okL","executionInfo":{"status":"ok","timestamp":1705167086557,"user_tz":-60,"elapsed":180,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}},"outputId":"0f81ee7f-8040-44fe-b595-a517c71142a5"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"gpt_model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  1248      \n","                                                                 \n"," positional_embedding (Embe  multiple                  0 (unused)\n"," dding)                                                          \n","                                                                 \n"," GPTBlock0 (GPTDecoderBlock  multiple                  0 (unused)\n"," )                                                               \n","                                                                 \n"," GPTBlock1 (GPTDecoderBlock  multiple                  0 (unused)\n"," )                                                               \n","                                                                 \n"," output (Dense)              multiple                  0 (unused)\n","                                                                 \n","=================================================================\n","Total params: 1248 (4.88 KB)\n","Trainable params: 1248 (4.88 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(\n","    optimizer='nadam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=[\"accuracy\"]\n",")"],"metadata":{"id":"lKtuobLc3waO","executionInfo":{"status":"ok","timestamp":1705167088658,"user_tz":-60,"elapsed":1,"user":{"displayName":"Floris Buyse","userId":"15555724134925172037"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=2,\n","    restore_best_weights=True\n",")\n","model.fit(train_set, validation_data=valid_set, epochs=20, callbacks=[early_stopping])"],"metadata":{"id":"PgzLrygb4SSt"},"execution_count":null,"outputs":[]}]}