{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cEinwqHQiDU1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxxXYDh_yxAG"},"outputs":[],"source":["import functools\n","\n","\n","DefaultConv = functools.partial(\n","    tf.keras.layers.Conv2D,\n","    kernel_size=(1,1), padding=\"same\",\n","    strides=(1,1), activation='relu'\n",")\n","\n","class InceptionModule(tf.keras.layers.Layer):\n","\n","  def __init__(self, filters11,\n","                     filters33_reduce, filters33,\n","                     filters55_reduce, filters55,\n","                     filters_pool_proj,\n","                     use_batch_norm=True,\n","                     **kwargs):\n","    super().__init__(**kwargs)\n","\n","    self.conv11 = DefaultConv(filters=filters11)\n","\n","    self.conv33_reduce = DefaultConv(filters=filters33_reduce)\n","    self.conv33 = DefaultConv(filters=filters33, kernel_size=(3,3))\n","\n","    self.conv55_reduce = DefaultConv(filters=filters55_reduce)\n","    self.conv55 = DefaultConv(filters=filters55, kernel_size=(5,5))\n","\n","    self.max_pool = tf.keras.layers.MaxPool2D(\n","        pool_size=(3,3), strides=1, padding='same')\n","    self.pool_proj = DefaultConv(filters=filters_pool_proj)\n","\n","    self.use_batch_norm = use_batch_norm\n","    if use_batch_norm:\n","      self.batch_norm = tf.keras.layers.BatchNormalization()\n","\n","  def call(self, x):\n","\n","    path1 = self.conv11(x)\n","\n","    path2 = self.conv33_reduce(x)\n","    path2 = self.conv33(path2)\n","\n","    path3 = self.conv55_reduce(x)\n","    path3 = self.conv55(path3)\n","\n","    path4 = self.max_pool(x)\n","    path4 = self.pool_proj(path4)\n","\n","    concatenation = tf.keras.layers.concatenate([path1, path2, path3, path4])\n","\n","    return self.batch_norm(concatenation) if self.use_batch_norm else concatenation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGmI2eY-1CzV"},"outputs":[],"source":["## Test dimensions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nc5UIip01FrU"},"outputs":[],"source":["X = tf.constant(0.0, shape=(1,28,28,192)) # batch of one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeFgrPxo1Y6i"},"outputs":[],"source":["inception3a = InceptionModule(filters11=64, filters33_reduce=96, filters33=128,\n","                              filters55_reduce=16, filters55=32,\n","                              filters_pool_proj=32, use_batch_norm=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5gx9tBZ1vxc"},"outputs":[],"source":["inception3a(X).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unoziT2K1p8E"},"outputs":[],"source":["total = 0\n","for w in inception3a.get_weights():\n","  total += w.size\n","\n","print(total)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4q_jvWlPQ6Kg"},"outputs":[],"source":["import functools\n","\n","DefaultMaxPool = functools.partial(\n","    tf.keras.layers.MaxPool2D,\n","    pool_size=(3,3), strides=(2,2), padding='same'\n",")\n","def get_googlenet_model(input_shape, num_classes, use_batch_norm=True, **kwargs):\n","\n","  model = tf.keras.Sequential(**kwargs)\n","\n","  model.add(tf.keras.layers.Conv2D(\n","      filters=64, kernel_size=7, strides=2, padding='same',\n","      activation='relu',\n","      input_shape=input_shape))\n","\n","  if use_batch_norm:\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","  model.add(DefaultMaxPool())\n","\n","  model.add(tf.keras.layers.Conv2D(\n","      filters=64, kernel_size=1, strides=1, padding='same', activation='relu'))\n","\n","  model.add(tf.keras.layers.Conv2D(\n","      filters=192, kernel_size=3, strides=1, padding='same', activation='relu'))\n","\n","  if use_batch_norm:\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","  model.add(DefaultMaxPool())\n","\n","\n","  filters11 = [64, 128]\n","  filters33_reduce = [96, 128]\n","  filters33 = [128, 192]\n","  filters55_reduce = [16, 32]\n","  filters55 = [32, 96]\n","  filter_pool_proj = [32, 64]\n","\n","  for (f11, f33r, f33, f55r, f55, fp) in zip(\n","      filters11, filters33_reduce, filters33, filters55_reduce, filters55, filter_pool_proj):\n","    model.add(InceptionModule(f11, f33r, f33, f55r, f55, fp, use_batch_norm=use_batch_norm))\n","\n","  model.add(DefaultMaxPool())\n","\n","  filters11 = [192, 160, 128, 112, 256]\n","  filters33_reduce = [96,112,128,144,160]\n","  filters33 = [208,224,256,288,320]\n","  filters55_reduce = [16,24,24,32,32]\n","  filters55 = [48,64,64,64,128]\n","  filter_pool_proj = [64,64,64,64,128]\n","\n","  for (f11, f33r, f33, f55r, f55, fp) in zip(\n","      filters11, filters33_reduce, filters33, filters55_reduce, filters55, filter_pool_proj):\n","    model.add(InceptionModule(f11, f33r, f33, f55r, f55, fp, use_batch_norm=use_batch_norm))\n","\n","  model.add(DefaultMaxPool())\n","\n","  filters11 = [256, 384]\n","  filters33_reduce = [160, 192]\n","  filters33 = [320, 384]\n","  filters55_reduce = [32, 48]\n","  filters55 = [128, 128]\n","  filter_pool_proj = [128, 128]\n","\n","  for (f11, f33r, f33, f55r, f55, fp) in zip(\n","      filters11, filters33_reduce, filters33, filters55_reduce, filters55, filter_pool_proj):\n","    model.add(InceptionModule(f11, f33r, f33, f55r, f55, fp, use_batch_norm=use_batch_norm))\n","\n","\n","  model.add(tf.keras.layers.GlobalAveragePooling2D())\n","\n","  model.add(tf.keras.layers.Dropout(0.4))\n","\n","  model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","  return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeQZ9WHrVsoJ"},"outputs":[],"source":["(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgzXaEjmYOd1"},"outputs":[],"source":["(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","X_train, X_valid = X_train_full[:-10000], X_train_full[-10000:]\n","y_train, y_valid = y_train_full[:-10000], y_train_full[-10000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drGSagbXWFS2"},"outputs":[],"source":["HEIGHT = 128\n","WIDTH = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPJ6b8cyYFEd"},"outputs":[],"source":["preprocess_layer = tf.keras.Sequential([\n","    tf.keras.layers.Resizing(HEIGHT, WIDTH, input_shape=(32,32,3)),\n","    tf.keras.layers.Rescaling(scale=1/127.5, offset=-1)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VBi-n2PYx9G"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","model = get_googlenet_model(\n","    input_shape=(128,128,3), num_classes=10,\n","    use_batch_norm=False,\n","    name=\"GoogLeNet\")\n","model.summary()\n","full_model = tf.keras.Sequential([\n","    preprocess_layer,\n","    model\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2Wpq2fyY50u"},"outputs":[],"source":["full_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BR_QgJKeZFzF"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","full_model.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsEP7EZBaPxd"},"outputs":[],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_accuracy\",\n","    min_delta=0.001,\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","history = full_model.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=128,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"kG2r7CIQdhOV"},"source":["We get 79.03 validation accuracy after 16 epochs"]},{"cell_type":"markdown","metadata":{"id":"p_DgmwyTfFOS"},"source":["Introduce batch normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnR61IZ8fIYJ"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","model_with_bn = get_googlenet_model(\n","    input_shape=(128,128,3), num_classes=10,\n","    use_batch_norm=True,\n","    name=\"GoogLeNetWithBN\")\n","model_with_bn.summary()\n","full_model_with_bn = tf.keras.Sequential([\n","    preprocess_layer,\n","    model_with_bn\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1QfbDK-fWGL"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","full_model_with_bn.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tRcmYkHfbMC"},"outputs":[],"source":["history = full_model_with_bn.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=128,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"cCAIdgoGk0_p"},"source":["82.70 validation accuraatheid na 20 epochs"]},{"cell_type":"markdown","metadata":{"id":"m4GuXbo8k7sI"},"source":["Try to add data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx-tNajhi8Si"},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n","    tf.keras.layers.RandomRotation(factor=0.05, seed=42),\n","    tf.keras.layers.RandomContrast(factor=0.2, seed=42)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hx36jD4lFcA"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","model_with_bn = get_googlenet_model(\n","    input_shape=(128,128,3), num_classes=10,\n","    use_batch_norm=True,\n","    name=\"GoogLeNetWithBN\")\n","model_with_bn.summary()\n","full_model_with_bn_and_da = tf.keras.Sequential([\n","    data_augmentation,\n","    preprocess_layer,\n","    model_with_bn\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rItMqVp4lQeX"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","full_model_with_bn_and_da.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRH-U7FllYn5"},"outputs":[],"source":["# Cell per ongeluk een tweede keer gestart maar snel terug gestopt\n","history = full_model_with_bn_and_da.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=128,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"rg9IpiJnvbeS"},"source":["88 percent validation accuracy after 38 epochs (ca. 50 seconds per epoch!)"]},{"cell_type":"markdown","metadata":{"id":"yhGrgOyJvllk"},"source":["Now try to lower the learning rate and see if it gets even better.\n","DO NOT recreate model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPLSO81Hvjg1"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001 * 0.1)\n","full_model_with_bn_and_da.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dqVTLMJvzrU"},"outputs":[],"source":["history = full_model_with_bn_and_da.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=128,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"ii7QdI6XzH86"},"source":["90.74 validation accuracy after 9 epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNDfC_6gzQt5"},"outputs":[],"source":["# Nog een keer verlagen\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001 * 0.1 * 0.1)\n","full_model_with_bn_and_da.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBM0xiYFzXP5"},"outputs":[],"source":["history = full_model_with_bn_and_da.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=128,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foUplvN-08nR"},"outputs":[],"source":["# evaluate on testdata\n","full_model_with_bn_and_da.evaluate(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"ZXgTCJHt1EZb"},"source":["90.10 % accuracy on the testdata"]},{"cell_type":"code","source":["# With Monte Carlo dropout.\n","# We remove the data augmentation layer, because later we will set training to True\n","# and the data augmentation layer should not be active during testing.\n","model_mc_dropout = tf.keras.Sequential([\n","    preprocess_layer,\n","    model_with_bn])"],"metadata":{"id":"LYB_nhPgmDsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","y_test_pred_mc = np.argmax(\n","    np.stack([model_mc_dropout(X_test, training=True) for _ in range(100)]).mean(axis=0),\n","    axis=-1)\n","\n","print(f\"Accuracy with MC dropout on test set: {np.mean(y_test_pred_mc == y_test.squeeze())}\")"],"metadata":{"id":"-QVYL72NmM8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The previous code results in Out of Memory Error"],"metadata":{"id":"cXRH6AN-mPtx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGNL378l2RNq"},"outputs":[],"source":["accuracies = []\n","TEST_BATCH_SIZE = 500\n","\n","for batch_nr in range(X_test.shape[0] // TEST_BATCH_SIZE):\n","  X_batch = X_test[batch_nr * TEST_BATCH_SIZE: (batch_nr + 1) * TEST_BATCH_SIZE]\n","  y_batch = y_test[batch_nr * TEST_BATCH_SIZE: (batch_nr + 1) * TEST_BATCH_SIZE]\n","\n","  # Restrict to 20 samples for speed\n","  y_test_pred_mc = np.argmax(\n","    np.stack([model_mc_dropout(X_batch, training=True) for _ in range(20)]).mean(axis=0),\n","    axis=-1)\n","\n","  accuracies.append(np.mean(y_test_pred_mc == y_batch.squeeze()))\n","\n","  print(\".\", end='', flush=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WqieLqYC39zh"},"outputs":[],"source":["np.mean(accuracies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLbP0v7J3VUZ","tags":[]},"outputs":[],"source":["# MC Dropout *with* data augementation\n","accuracies = []\n","TEST_BATCH_SIZE = 500\n","\n","for batch_nr in range(X_test.shape[0] // TEST_BATCH_SIZE):\n","  X_batch = X_test[batch_nr * TEST_BATCH_SIZE: (batch_nr + 1) * TEST_BATCH_SIZE]\n","  y_batch = y_test[batch_nr * TEST_BATCH_SIZE: (batch_nr + 1) * TEST_BATCH_SIZE]\n","\n","  # Restrict to 20 samples for speed\n","  y_test_pred_mc = np.argmax(\n","    np.stack([full_model_with_bn_and_da(X_batch, training=True) for _ in range(20)]).mean(axis=0),\n","    axis=-1)\n","\n","  accuracies.append(np.mean(y_test_pred_mc == y_batch.squeeze()))\n","\n","  print(\".\", end='', flush=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"brUE4boikIqE"},"outputs":[],"source":["np.mean(accuracies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTvD_mfnkIqE"},"outputs":[],"source":["## 90.79% with data augmentation and MC dropout!"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}