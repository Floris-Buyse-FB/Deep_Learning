{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fSi0fVIfsI3K"},"outputs":[],"source":["import functools\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"ycqLoenbtYxf"},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rv0TY8ykseU-"},"outputs":[],"source":["(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a41tOFggsnqH"},"outputs":[],"source":["print(X_train_full.shape)\n","print(y_train_full.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkyxNzQztBNf"},"outputs":[],"source":["X_train, X_valid = X_train_full[:-10000], X_train_full[-10000:]\n","y_train, y_valid = y_train_full[:-10000], y_train_full[-10000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7Vhwow6tRgn"},"outputs":[],"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_valid.shape)\n","print(y_valid.shape)"]},{"cell_type":"markdown","metadata":{"id":"H1E4tlittacn"},"source":["## Some Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvvnKr7Kt5Bf"},"outputs":[],"source":["# Number of examples in each category\n","np.array(np.unique(y_train, return_counts=True)).T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3h5lFGmwnz2"},"outputs":[],"source":["class_names = (['airplane', 'automobile', 'bird', 'cat', 'deer'] +\n","   ['dog', 'frog', 'horse', 'ship', 'truck']\n",")\n","\n","plt.figure(figsize=(10,10))\n","\n","for i in range(25):\n","  ax = plt.subplot(5, 5, i + 1)\n","  plt.imshow(X_train[i])\n","  plt.title(f\"{class_names[y_train[i][0]]}\")\n","  plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"yq10f8X5xFzm"},"source":["## Build a model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OopxCPBYxH7-"},"outputs":[],"source":["# Define a convolutional layer with default parameters\n","DefaultConv2D = functools.partial(tf.keras.layers.Conv2D,\n","    kernel_size=(3,3),\n","    strides=(1,1),\n","    activation='relu',\n","    padding='same'\n",")\n","\n","tf.keras.backend.clear_session()\n","def get_model():\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Rescaling(scale=1./255, input_shape=(32,32,3)))\n","\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-gTKnol1noW"},"outputs":[],"source":["model = get_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"C9Lafp-G2BN_"},"source":["## Compile the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMYhHou62IGV"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1Wr2jee2WG2"},"outputs":[],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_accuracy\",\n","    min_delta=0.001,\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","history = model.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pS6XEAfw3eou"},"outputs":[],"source":["def plot_learning_curves(history):\n","  plt.figure(figsize=(8, 5))\n","  for key, style in zip(history.history, [\"r-o\", \"r-*\", \"b-o\", \"b-*\"]):\n","    epochs = np.array(history.epoch)\n","    plt.plot(epochs + 1, history.history[key], style, label=key)\n","  plt.xlabel(\"Epoch\")\n","  plt.axis([1, len(history.history['loss']), 0., 1])\n","  plt.legend(loc=\"lower left\")\n","  plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3vAr5Pc3imm"},"outputs":[],"source":["plot_learning_curves(history)"]},{"cell_type":"markdown","metadata":{"id":"RiSDyidZ38M_"},"source":["### Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cqenOmy3-Te"},"outputs":[],"source":["model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHgjplrXg0be"},"outputs":[],"source":["model.evaluate(X_valid, y_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DssdjTjm4ix2"},"outputs":[],"source":["def evaluate_model(X, predictions, y_true):\n","  # X (n, image_shape): the images\n","  # predictions made by the model (n, #num_classes)\n","  # y_true: actual labels (n, 1)\n","\n","  # Returns: three lists\n","  # incorrectly_classified_images, predicted_labels, expected_labels\n","\n","  assert X.shape[0] == predictions.shape[0] == y_true.shape[0], \"dimensions wrong\"\n","\n","  incorrectly_classified_images = []\n","  expected_labels = []\n","  predicted_labels = []\n","\n","  y_predicted = np.argmax(predictions, axis=-1)\n","\n","  for i in range(y_true.shape[0]):\n","    if y_predicted[i] != y_true[i]:\n","      incorrectly_classified_images.append(X[i])\n","      expected_labels.append(y_true[i,0])\n","      predicted_labels.append(y_predicted[i])\n","\n","  return incorrectly_classified_images, predicted_labels, expected_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_uIxqSj5D2G"},"outputs":[],"source":["y_test_predictions = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndaeMqxa5J5e"},"outputs":[],"source":["incorrectly_classified_images, predicted_labels, expected_labels = (\n","    evaluate_model(X_test, y_test_predictions, y_test)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuZ9RsfR5U_H"},"outputs":[],"source":["plt.figure(figsize=(12,12))\n","\n","for i in range(25):\n","  ax = plt.subplot(5, 5, i + 1)\n","  plt.imshow(incorrectly_classified_images[i])\n","  plt.title(f\"p: {class_names[predicted_labels[i]]} e: {class_names[expected_labels[i]]}\")\n","  plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3vDSgjC6m0e"},"outputs":[],"source":["y_test_class_predictions = np.argmax(y_test_predictions, axis=-1)\n","y_test_class_predictions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1LEA-SO6zIO"},"outputs":[],"source":["y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3GWAZqx7UBm"},"outputs":[],"source":["# Create a confusion matrix using tensorflow\n","cm = tf.math.confusion_matrix(y_test.squeeze(), y_test_class_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLatwTkQ8AD_"},"outputs":[],"source":["ax= plt.subplot()\n","sns.heatmap(cm, annot=True, fmt='g', ax=ax, cbar=False);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n","ax.set_title('Confusion Matrix');\n","ax.xaxis.set_ticklabels(class_names,  rotation=-45);\n","ax.yaxis.set_ticklabels(class_names, rotation=0);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0KtpX-f99R3"},"outputs":[],"source":["# Sanity check that the labels on the confusion matrix are correct\n","my_cm = np.zeros(shape=(10,10),dtype=np.int32)\n","for (true_label, pred_label) in zip(y_test.squeeze(), y_test_class_predictions):\n","  my_cm[true_label, pred_label] += 1\n","\n","my_cm"]},{"cell_type":"markdown","metadata":{"id":"W4naou7Y-rhG"},"source":["### Improve the model\n","\n","This part of the assignment is a lot more open ended than the parts above.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hh-I-tYi-t6t"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","def get_model_additional_block():\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Rescaling(scale=1./255, input_shape=(32,32,3)))\n","\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bj9_aDwh--eG"},"outputs":[],"source":["model2 = get_model_additional_block()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model2.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model2.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"markdown","metadata":{"id":"S0ph9M4FFFJu"},"source":["Doesn't seem to make much of a difference on the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gy8lP55HFVSe"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","def get_model_he():\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Rescaling(scale=1./255, input_shape=(32,32,3)))\n","\n","  model.add(DefaultConv2D(filters=32, kernel_initializer=\"he_uniform\"))\n","  model.add(DefaultConv2D(filters=32, kernel_initializer=\"he_uniform\"))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(DefaultConv2D(filters=64, kernel_initializer=\"he_uniform\"))\n","  model.add(DefaultConv2D(filters=64, kernel_initializer=\"he_uniform\"))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=128, activation='relu',\n","                                  kernel_initializer=\"he_uniform\"))\n","  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPyfOd_IFnUO"},"outputs":[],"source":["model3 = get_model_he()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model3.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model3.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSIFp1Y2hg81"},"outputs":[],"source":["print(f\"Base model {model.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model {model2.evaluate(X_valid, y_valid)}\")\n","print(f\"Base model with he initialization {model3.evaluate(X_valid, y_valid)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61nVSYMPhyoU"},"outputs":[],"source":["# Add dropout to the model with extra conv block after each max pooling layer\n","tf.keras.backend.clear_session()\n","def get_model_additional_block_with_dropout():\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Rescaling(scale=1./255, input_shape=(32,32,3)))\n","\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONqsyUz8iVk9"},"outputs":[],"source":["model4 = get_model_additional_block_with_dropout()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model4.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model4.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2esqXT2djjue"},"outputs":[],"source":["print(f\"Base model {model.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model {model2.evaluate(X_valid, y_valid)}\")\n","print(f\"Base model with he initialization {model3.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model with dropout {model4.evaluate(X_valid, y_valid)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Rs5Cvk9PjyF1"},"source":["Adding dropout increased performance by 2 percentage points on the validation dataset.\n","Let's try to add some more dropout, e.g. after the dense layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thXETOy7j_Yc"},"outputs":[],"source":["# Add dropout to the model with extra conv block after each max pooling layer\n","tf.keras.backend.clear_session()\n","def get_model_additional_block_with_dropout2():\n","  model = tf.keras.models.Sequential()\n","\n","  model.add(tf.keras.layers.Rescaling(scale=1./255, input_shape=(32,32,3)))\n","\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(DefaultConv2D(filters=32))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(DefaultConv2D(filters=64))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(DefaultConv2D(filters=128))\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=2))\n","  model.add(tf.keras.layers.Dropout(rate=0.2))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","  model.add(tf.keras.layers.Dropout(rate=0.2)) # More dropout\n","\n","  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CerS1h7vkMGU"},"outputs":[],"source":["model5 = get_model_additional_block_with_dropout()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model5.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model5.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ult-P3tMk420"},"outputs":[],"source":["print(f\"Base model {model.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model {model2.evaluate(X_valid, y_valid)}\")\n","print(f\"Base model with he initialization {model3.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model with dropout {model4.evaluate(X_valid, y_valid)}\")\n","print(f\"Extra conv block model with dropout2 {model5.evaluate(X_valid, y_valid)}\")"]},{"cell_type":"markdown","metadata":{"id":"5lfnPuDslECs"},"source":["Adding additional dropout didn't seem to help a lot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FL7f7fVzlH3E"},"outputs":[],"source":["# Try to improve `model4` by training it with a lower learning rate.\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001 * 0.1) # lower learning rate by factor 0.1\n","# Continue training the model from the current weights, do NOT instantiate the model anew\n","model4.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model4.fit(X_train, y_train,\n","          validation_data=(X_valid, y_valid),\n","          epochs=100,\n","          batch_size=32,\n","          callbacks=[early_stopping]\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tNMF0DOmNR0"},"outputs":[],"source":["print(f\"Extra conv block model with dropout train longer {model4.evaluate(X_valid, y_valid)}\")\n","# Van 78.32% naar 80.50%, Een extra 2 procentpunten."]},{"cell_type":"markdown","metadata":{"id":"3qUNOr3lmY8c"},"source":["Let's try Monte Carlo dropout. This is slow but should also increase performance?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ik3uwuP7miHd"},"outputs":[],"source":["# Let's try 100 samples\n","y_probas = np.stack([model4(X_valid, training=True) for _ in range(100)])\n","y_probas.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQYXBWK7nw9F"},"outputs":[],"source":["y_proba = y_probas.mean(axis=0)\n","y_proba.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02FTzkvyoJOk"},"outputs":[],"source":["y_valid_pred_mc = np.argmax(y_proba, axis=-1)\n","y_valid_pred_mc.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oychynuOoRhN"},"outputs":[],"source":["\n","print(f\"Accuracy with MC dropout on validation set: {np.mean(y_valid_pred_mc == y_valid.squeeze())}\")"]},{"cell_type":"markdown","metadata":{"id":"7ymojVmTowYe"},"source":["Monte Carlo dropout gained us another 0.8 percentage points.\n","\n","Let's evaluate with MC dropout on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MM3oyEPspOU0"},"outputs":[],"source":["y_test_pred_mc = np.argmax(\n","    np.stack([model4(X_test, training=True) for _ in range(100)]).mean(axis=0),\n","    axis=-1)\n","\n","print(f\"Accuracy with MC dropout on test set: {np.mean(y_test_pred_mc == y_test.squeeze())}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qArTN2wdp6r8"},"outputs":[],"source":["# Evaluate model on the test set without MC dropout\n","model4.evaluate(X_test, y_test)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}