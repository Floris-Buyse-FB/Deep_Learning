{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tzSDP45IiRl-"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"lHjlUReQcROj"},"source":["### Definition of the cell.\n","\n","Make sure to add layers in this order\n","\n","- `input`\n","- `forget`\n","- `carry`\n","- `output`\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Tut9WXQiWQi"},"outputs":[],"source":["class MyLSTMCell(tf.keras.layers.Layer):\n","\n","  def __init__(self, units, **kwargs):\n","    super().__init__(**kwargs)\n","\n","    self.state_size = [units,units]\n","    self.output_size = units\n","\n","    self.dense_i = tf.keras.layers.Dense(\n","        units=units,\n","        bias_initializer=\"zeros\",\n","        activation=\"sigmoid\")\n","\n","    self.dense_f = tf.keras.layers.Dense(\n","        units=units,\n","        bias_initializer=\"ones\",\n","        activation=\"sigmoid\")\n","\n","    self.dense_g = tf.keras.layers.Dense(\n","        units=units,\n","        bias_initializer=\"zeros\",\n","        activation=\"tanh\")\n","\n","    self.dense_o = tf.keras.layers.Dense(\n","        units=units,\n","        bias_initializer=\"zeros\",\n","        activation=\"sigmoid\")\n","\n","  def call(self, inputs, outputs):\n","    memory_state = outputs[0] # h\n","    carry_state = outputs[1]  # c\n","\n","    inputs_and_memory = tf.concat([inputs, memory_state], axis=-1)\n","\n","    i = self.dense_i(inputs_and_memory)\n","    f = self.dense_f(inputs_and_memory)\n","    g = self.dense_g(inputs_and_memory)\n","    o = self.dense_o(inputs_and_memory)\n","\n","    new_carry_state = f * carry_state + i * g\n","    y = o * tf.keras.activations.tanh(new_carry_state)\n","\n","    return y, [y, new_carry_state]"]},{"cell_type":"markdown","metadata":{"id":"BS0Yex6VcrMs"},"source":["### Optional: Check implementation\n","\n","The implementation of `MyLSTMCell` is checked by comparing it to the working of the built-in `LSTMCell` of Keras.\n","\n","We initialize both cells with the same weights and then run them througth a RNN and see whether they give the same output for the same input."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"klDHhM2HnDgM"},"outputs":[],"source":["BATCH_SIZE = 5\n","NUM_STEPS = 10\n","NUM_FEATURES = 3\n","UNITS=4\n","# Some random input\n","inputs = tf.random.normal([BATCH_SIZE, NUM_STEPS, NUM_FEATURES])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0jMJYXnuen0"},"outputs":[],"source":["# Check the output shape of running the cell\n","my_lstm_cell = MyLSTMCell(UNITS)\n","rnn = tf.keras.layers.RNN(my_lstm_cell)\n","output = rnn(inputs)\n","output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rARcLmfLofJQ"},"outputs":[],"source":["# Do the same for the built-in LSTMCell in Keras\n","cell = tf.keras.layers.LSTMCell(UNITS)\n","rnn2 = tf.keras.layers.RNN(cell)\n","output2 = rnn2(inputs)\n","output2.shape"]},{"cell_type":"markdown","metadata":{"id":"F9qbw38SdTaZ"},"source":["The internal implementation of LSTMCell is different. It doesn't use `Dense` layers and organizes the weights into three tensors: `kernel`, `recurrent_kernel` and `bias`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1ki71EdlTF3"},"outputs":[],"source":["# Retrieve the weigths and check their shapes\n","kernel_weights, recurrent_kernel_weights, bias = rnn2.get_weights()\n","kernel_weights.shape, recurrent_kernel_weights.shape, bias.shape"]},{"cell_type":"markdown","metadata":{"id":"rLOs-EiBd_xL"},"source":["Our implementation of an LSTM cell organizes the weights into 8 tensors (4 Dense layers with 2 weight tensors each)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Dw-9fcBvp01"},"outputs":[],"source":["# Loop over the weights and print their size\n","for w in rnn.get_weights():\n","  print(w.shape)"]},{"cell_type":"markdown","metadata":{"id":"JdJaBuztfEvM"},"source":["Get the weights from our implementation and name them.\n","The order in which they were created matters!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBwp5Ygcwb42"},"outputs":[],"source":["rnn_weights = rnn.get_weights()\n","i_w = rnn_weights[0]\n","i_b = rnn_weights[1]\n","f_w = rnn_weights[2]\n","f_b = rnn_weights[3]\n","c_w = rnn_weights[4]\n","c_b = rnn_weights[5]\n","o_w = rnn_weights[6]\n","o_b = rnn_weights[7]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnTxthRbww4n"},"outputs":[],"source":["bias = tf.concat(values=[i_b, f_b, c_b, o_b],axis=-1)\n","kernel = tf.concat(values=[i_w[:NUM_FEATURES], f_w[:NUM_FEATURES], c_w[:NUM_FEATURES], o_w[:NUM_FEATURES]], axis=-1)\n","recurrent_kernel = tf.concat(values=[i_w[NUM_FEATURES:], f_w[NUM_FEATURES:], c_w[NUM_FEATURES:], o_w[NUM_FEATURES:]], axis=-1)\n","bias.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2sUODgPxaRZ"},"outputs":[],"source":["# Set the weights on RNN2\n","rnn2.set_weights([kernel, recurrent_kernel,   bias])"]},{"cell_type":"markdown","metadata":{"id":"B9jZhX-tfvEt"},"source":["Check that the result of running both RNNs is the same.  Eyeball the results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUh43hYqxfax"},"outputs":[],"source":["rnn2(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKqlGSSyxk_B"},"outputs":[],"source":["rnn(inputs)"]},{"cell_type":"markdown","metadata":{"id":"btZEX_3Xg3MG"},"source":["Use `tf.debugging.assert_near` to check that the results are actually \"equal\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIh0kw7Mgb-N"},"outputs":[],"source":["\n","tf.debugging.assert_near(rnn2(inputs), rnn(inputs))\n","print(\"OK\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}